{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "# If you didn't set an environment variable, you could do:\n",
    "# client = openai.OpenAI(api_key=\"sk-your-api-key\")  # (Not recommended to hard-code in real apps)\n",
    "\n",
    "# Define a function to generate a response from the AI given a user message\n",
    "def generate_response(user_prompt):\n",
    "    \"\"\"\n",
    "    Sends the user prompt to OpenAI and returns the AI's response.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_prompt : str\n",
    "        The input message from the user.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The AI-generated response as plain text.\n",
    "    \"\"\"\n",
    "    # Use OpenAI's chat completion endpoint to get a chat-based response\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # The AI model to use\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]  # The conversation context\n",
    "    )\n",
    "    # Extract the assistant's message from the response\n",
    "    message_text = response.choices[0].message.content\n",
    "    return message_text  # Return the assistant's reply\n",
    "\n",
    "# Quick test: let's see if the function works by asking a sample question\n",
    "test_reply = generate_response(\"Hello, how are you?\")\n",
    "print(test_reply)  # This should print an AI-generated response, e.g., \"Hello! I'm doing well, how can I assist you?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st  # Import Streamlit for the UI\n",
    "\n",
    "# Set the configuration of the page\n",
    "st.set_page_config(\n",
    "    page_title=\"AI Chatbot\",   # Title of the web page\n",
    "    page_icon=\"\",           # An icon for the page (emoji of a robot)\n",
    "    layout=\"wide\"             # Use the full width of the page for a wide layout\n",
    ")\n",
    "\n",
    "# Add a title to the app\n",
    "st.title(\" AI Chatbot Assistant\")\n",
    "st.markdown(\"**Welcome!** Ask anything or upload a file for the bot to analyze.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sidebar section for file upload\n",
    "uploaded_file = st.sidebar.file_uploader(\n",
    "    \"Upload a file (optional):\",  # Label for the uploader\n",
    "    type=[\"txt\", \"pdf\"]           # Limit file types to text or PDF for this example\n",
    ")\n",
    "\n",
    "# If a file is uploaded, we can read or process it (here we just show the file name for confirmation)\n",
    "if uploaded_file is not None:\n",
    "    file_details = f\"**{uploaded_file.name}** ({uploaded_file.size} bytes)\"\n",
    "    st.sidebar.write(\"Uploaded file:\", file_details)\n",
    "    # In a real app, you might pass this file's content to the AI or do something with it.\n",
    "    # For example, if it's a text file you could do: text = uploaded_file.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chat history in session state if not already there\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []  # list to hold all messages (dicts with 'role' and 'content')\n",
    "\n",
    "# (Optional) If we want the bot to start with a greeting message, we can add an initial assistant message:\n",
    "if not st.session_state.messages:\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": \"Hello! I'm here to help. Feel free to ask me anything or upload a file for analysis.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all past messages in the chat\n",
    "for msg in st.session_state.messages:\n",
    "    if msg[\"role\"] == \"assistant\":\n",
    "        # Display assistant messages on the left (default)\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            st.markdown(msg[\"content\"])\n",
    "    else:\n",
    "        # Display user messages on the right side\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(msg[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat input widget (appears at the bottom of the page)\n",
    "user_message = st.chat_input(\"Type your message here...\")\n",
    "\n",
    "if user_message:\n",
    "    # 1. Add the user message to chat history\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    # 2. Display the user message immediately (so it appears in the chat above)\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_message)\n",
    "    \n",
    "    # 3. Generate the AI's response (this might take a moment)\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):  # Show a spinner while waiting for the AI\n",
    "            assistant_reply = generate_response(user_message)\n",
    "            st.markdown(assistant_reply)\n",
    "    # 4. Add the assistant's reply to the chat history\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": assistant_reply})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py (full code combining all steps)\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import streamlit as st\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def generate_response(user_prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    message_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return message_text\n",
    "\n",
    "st.set_page_config(page_title=\"AI Chatbot\", page_icon=\"\", layout=\"wide\")\n",
    "st.title(\" AI Chatbot Assistant\")\n",
    "st.markdown(\"**Welcome!** Ask anything or upload a file for the bot to analyze.\")\n",
    "\n",
    "uploaded_file = st.sidebar.file_uploader(\"Upload a file (optional):\", type=[\"txt\", \"pdf\"])\n",
    "if uploaded_file is not None:\n",
    "    st.sidebar.write(\"Uploaded file:\", f\"**{uploaded_file.name}** ({uploaded_file.size} bytes)\")\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "if not st.session_state.messages:\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": \"Hello! I'm here to help. Feel free to ask me anything or upload a file.\"})\n",
    "\n",
    "# Display existing chat messages\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.markdown(msg[\"content\"])\n",
    "\n",
    "# Chat input widget for new messages\n",
    "if user_msg := st.chat_input(\"Type your message here...\"):\n",
    "    # Add user message to history and display it\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(user_msg)\n",
    "    # Generate assistant response with spinner\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            assistant_msg = generate_response(user_msg)\n",
    "            st.markdown(assistant_msg)\n",
    "    # Add assistant response to history\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": assistant_msg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in your terminal, not in this notebook\n",
    "# streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"720\" controls>\n",
    "  <source src=\"assets/streamlit_chatbot_video.mp4\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
